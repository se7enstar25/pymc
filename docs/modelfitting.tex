PyMC probability models are linked collections of nodes. The constituent nodes of these models are only really aware of their parents: given values for their parents \texttt{Deterministic} instances can compute their values, \texttt{Stochastic} instances can compute their log-probabilities or draw new values, and \texttt{Potential} instances can compute their log-probabilities. Since all useful computations with probability models require larger-scale coordination and communication, the models we have created so far are fairly inert.

All objects that fit probability models are descended from the \texttt{Model} class. All objects that fit probability models using some kind of Monte Carlo method are descended from the \texttt{Model} subclass \texttt{Sampler}. \texttt{Sampler} provides a generic sampling loop method and database support for storing large sets of joint samples. Sampling loops can optionally be run interactively, meaning the user can pause sampling at any time, return to the Python prompt, check progress, and make adjustments.

Currently, PyMC provides three classes that actually fit models:
\begin{itemize}
    \item \texttt{MAP}, which computes maximum a posteriori estimates.
    \item \texttt{NormApprox}, which computes the `normal approximation' \cite{gelman}: the joint distribution of all stochastic variables in a model is approximated as normal using local information at the maximum a posteriori estimate.
    \item \texttt{MCMC}, which is coordinates Markov Chain Monte Carlo algorithms. The actual work of updating stochastic variables conditional on the rest of the model is done by \texttt{StepMethod} instances, which are described in this chapter.
\end{itemize}
This set will hopefully grow in future releases. 



\section{The \texttt{Model} class} \label{sec:Model}
This class serves as a container for probability models and as a base class for the classes responsible for model fitting, such as \texttt{MCMC}. It can also be useful for computing Bayes factors.

Models' useful methods are:
\begin{description}
    \item[\texttt{draw_from_prior()}:] Sets all stochastic variables' values to new random values, which would be a sample from the joint distribution if all data and \texttt{Potential} instances' log-probability attributes were set to zero.
    \item[\texttt{seed()}:] Same as \texttt{draw_from_prior}, but only stochastic variables with an \texttt{rseed} attribute are changed.
    \item[\texttt{find_generations():}] Sets the \texttt{generations} attribute. This attribute is a list whose elements are sets of stochastic variables. The zeroth set has no extended parents in the model, the first set only has extended parents in the zeroth set, and so on.
\end{description}

The helper functions \texttt{weight} and \texttt{graph} act on models. \texttt{weight} computes Bayes' factors (posterior probabilities of model correctness) for lists of models using the \texttt{draw_from_prior} method, and \texttt{graph} produces graphical representations; see section \ref{sec:graphical}. The \texttt{weight} function's algorithm can only be expected to perform well when the dimension of the parameter space is small (less than about 10).

Models inherit the following attributes from \texttt{ContainerBase}:
\begin{itemize}
    \item \texttt{variables}
    \item \texttt{stochastics}
    \item \texttt{potentials}
    \item \texttt{deterministics}
    \item \texttt{data_stochastics}
    \item \texttt{step_methods}
    \item \texttt{value}
\end{itemize}

% In addition, models expose each node they contain as an attribute. For instance, if model \texttt{M} were produced from model (\ref{disastermodel}) \texttt{M.s} would return the switchpoint variable. It's a good idea to give each variable a unique \texttt{__name__} attribute if you want to access them this way.

In future releases, \texttt{Model} will provide graphical services such as finding maximal cliques and junction trees.


\subsection{Instantiation of models} \label{sec:ModelInstantiation}
The \texttt{Model} class's init method takes the following arguments:
\begin{description}
    \item[\texttt{input}:] Some collection of PyMC nodes defining a probability model. These may be stored in a list, set, tuple, dictionary, array, module, or any object with a \texttt{__dict__} attribute. If \texttt{input} is \texttt{None} (the default), all the nodes on the main namespace and the \texttt{Model} object's class's dictionary are collected.
    \item[\texttt{output_path} (optional):] A string indicating where all of the files produced by the model should be saved by default.
    \item[\texttt{verbose} (optional):] An integer controlling the verbosity of the model's output.
\end{description}
The input argument can be just about anything; once you have defined the nodes that make up your model, you shouldn't even have to think about how to wrap them in a \texttt{Model} instance. Some examples of model instantiation, using nodes \texttt{a}, \texttt{b} and \texttt{c}:
\begin{itemize}
    \item \texttt{M = Model(a,b,c)}
    \item \texttt{M = Model(set([a,b,c]))}
    \item \texttt{M = Model(\{'a': a, 'd': [b,c]\})}
    \item \texttt{M = Model([[a,b],c])}
    \item Here module \texttt{MyModule} contains the definitions of \texttt{a}, \texttt{b} and \texttt{c}:\begin{verbatim}
import MyModule
M = Model(MyModule)
    \end{verbatim}
    \item This is a useful way to make a `model factory' using input parameters:
    \begin{verbatim}
def make_model(x):
    a = Exponential('a',.5,beta=x)
    
    @deterministic
    def b(a=a):
        return 100-a
    
    @stochastic
    def c(value=.5, a=a, b=b);
        return (value-a)**2/b
        
    return locals()
    
M = Model(make_model(3))
    \end{verbatim}
    \item Model subclasses are inspected for nodes:
    \begin{verbatim}
class MyModel(Model):
    a = Exponential('a',.5,beta=x)

    @deterministic
    def b(a=a):
        return 100-a

    @stochastic
    def c(value=.5, a=a, b=b);
        return (value-a)**2/b        
        
M = MyModel()
    \end{verbatim}    
    \item If no input argument is provided, the main namespace is inspected for nodes:
    \begin{verbatim}
    a = Exponential('a',.5,beta=x)

    @deterministic
    def b(a=a):
        return 100-a

    @stochastic
    def c(value=.5, a=a, b=b);
        return (value-a)**2/b        
    
    M = Model()
    \end{verbatim}

\end{itemize}

\section{The \texttt{Sampler} class} 
Samplers fit models with Monte Carlo fitting methods, which characterize the posterior distribution by approximate samples from it. They are initialized as follows: \texttt{Sampler(input, db='ram', output\_path=None, verbose=0)}. The \texttt{db} argument indicates which database backend should be used to store the samples (see chapter \ref{chap:database}), and the other three arguments are the same as for \texttt{Model}. Samplers have the following useful methods:
\begin{description}
    \item[\texttt{sample(iter, length=None, verbose=0)}:] Samples from the joint distribution. The \texttt{iter} argument controls how many times the sampling loop should be run, and the \texttt{length} argument controls the initial size of the database that will be used to store the samples.
    \item[\texttt{isample(iter, length=None, verbose=0)}:] The same as \texttt{sample}, but the sampling is done interactively: the user can pause sampling at any point and be returned to the Python prompt to inspect progress and adjust fitting parameters. While sampling is paused, the following methods are useful: 
    \begin{description}
        \item[\texttt{icontinue()}:] Continue interactive sampling.
        \item[\texttt{halt()}:] Truncate the database and clean up.
    \end{description}
    \item[\texttt{tally()}:] Write all variables' current values to the database.
    \item[\texttt{draw()}:] Not currently used. In future Monte Carlo fitting methods that aren't MCMC, such as importance samplers, the \texttt{draw()} method will be responsible for drawing approximate samples from the joint distribution (by setting the values all the stochastic variables in the model).
    \item[\texttt{save\_state()}:] Saves the current state of the sampler, including all stochastics, to the database. This allows the sampler to be reconstituted at a later time to resume sampling.
    \item[\texttt{restore\_state()}:] Restores the sampler to the state stored in the database.
    \item[\texttt{plot()}:] Generates densities (or histograms) and trace plots of all nodes in the sampler.
	 \item[\textttt{stats()}:] Generate summary statistics for all nodes in the model.
    \item[\texttt{remember(trace\_index)}:] Set all variables' values from frame \texttt{trace\_index} in the database.
\end{description}

\section{Maximum a posteriori estimates} 

The \texttt{MAP} class sets all stochastic variables to their maximum a posteriori values using functions in SciPy's \texttt{optimize} package. Scipy must be installed to use it. A \texttt{MAP} instance \texttt{N} can be created as follows:
\begin{verbatim}
N = MAP(input, eps=.001, diff_order = 5)    
\end{verbatim}
The parameters \texttt{eps} and \texttt{diff_order} control numerical differentiation. \texttt{diff_order}, which must be an integer, specifies the order of the numerical approximation (see the SciPy function \texttt{derivative}). The step size for numerical derivatives is controlled by \texttt{eps}, which may be either a single value or a dictionary of values keyed by variable (actual objects, not names). \texttt{MAP} requires all stochastic variables in \texttt{input} to be either float-valued or array-valued with dtype float, unlike PyMC in general.

\texttt{MAP} has two useful methods:
\begin{description}
    \item[\texttt{fit(method ='fmin', iterlim=1000, tol=.0001)}:] The optimization method may be \texttt{fmin}, \texttt{fmin_l_bfgs_b}, \texttt{fmin_ncg}, \texttt{fmin_cg}, or \texttt{fmin_powell}. See the documentation of SciPy's optimize package for the details of these methods. The \texttt{tol} and \texttt{iterlim} parameters are passed to the optimization function under the appropriate names.
    \item[\texttt{revert_to_max()}:] If the values of the constituent stochastic variables change after fitting, this function will reset them to their maximum a posteriori values.
\end{description}

The useful attributes of \texttt{MAP} are:
\begin{description}
    \item[\texttt{logp}:] The joint log-probability of the model.
    \item[\texttt{logp_at_max}:] The maximum joint log-probability of the model.
    \item[\texttt{len}:] The total number of elements in all the stochastic variables in the model with \texttt{isdata=False}.
    \item[\texttt{data_len}:] The total number number of elements in all the stochastic variables in the model with \texttt{isdata=True}.
    \item[\texttt{AIC}:] Akaike's information criterion for this model \textbf{cite}.
    \item[\texttt{BIC}:] The Bayesian information criterion for this model \textbf{cite}.
\end{description}

One use of the \texttt{MAP} class is finding reasonable initial states for MCMC chains; multiple \texttt{Model} subclasses can handle the same collection of nodes.

\section{Normal approximations} 

The \texttt{NormApprox} class extends the \texttt{MAP} class by approximating the posterior covariance of the model using the Fisher information matrix, or the Hessian of the joint log probability at the maximum. In addition to the methods and attributes of \texttt{MAP}, it provides the following methods inherited from \texttt{Sampler}:
\begin{description}
    \item[\texttt{sample(iter)}:] Samples from the approximate posterior distribution are drawn and stored.
    \item[\texttt{isample(iter)}:] An `interactive' version of \texttt{sample()}: sampling can be paused, returning control to the user.
\end{description}
It provides the following additional attributes:
\begin{description}
    \item[mu:] A special dictionary-like object that can be keyed with multiple variables. \texttt{N.mu[p1, p2, p3]} would return the approximate posterior mean values of stochastic variables \texttt{p1}, \texttt{p2} and \texttt{p3}, ravelled and concatenated to form a vector.
    \item[C:] Another special dictionary-like object. \texttt{N.C[p1, p2, p3]} would return the approximate posterior covariance matrix of stochastic variables \texttt{p1}, \texttt{p2} and \texttt{p3}. As with \texttt{mu}, these variables' values are ravelled and concatenated before their covariance matrix is constructed.
\end{description}

\section{Markov Chain Monte Carlo: the \texttt{MCMC} class}
 \texttt{MCMC} is a subclass of \texttt{Sampler}. At the beginning of a sampling loop, it assigns a \texttt{StepMethod} instance (section \ref{sec:stepmethod}) to each stochastic variable for which the user has not created one. Step methods are assigned as follows: each \texttt{StepMethod} subclass in existence is allowed to inspect the variable in question and determine its competence to handle the variable, on a scale of 0 to 3. An instance of the highest bidder is created to handle the variable.

MCMC samplers have the following methods, in addition those of \texttt{Sampler}:
\begin{description}
    \item[\texttt{sample(iter, burn=0, thin=1, tune\_interval=1000, verbose=0)}:] The \texttt{iter} argument controls the total number of MCMC iterations. No tallying will be done during the first \texttt{burn} iterations; these samples will be forgotten. After this burn-in period, tallying will be done each \texttt{thin} iterations. Tuning will be done each \texttt{tune\_interval} iterations. \textbf{Cite paper that says it's OK to keep tuning.}
    \item[\texttt{isample(iter, burn=0, thin=1, tune\_interval=1000, verbose=0)}:] See \texttt{Sampler.isample}.
    \item[\texttt{use_step_method(method, *args, **kwargs)}:] Creates an instance of step method class \texttt{method} to handle some stochastic variables. The extra arguments are passed to the init method.
    \item[\texttt{assign_step_methods()}:] Assigns step methods now. This method is called whenever \texttt{sample} or \texttt{isample} is called, but it can be useful to call it directly to see what the default step methods will be.
    \item[\texttt{tune()}:] Each step method's \texttt{tune} method is called. This method is called periodically throughout the sampling loop.
    \item[\texttt{goodness()}:] \textbf{Someone else document this}
\end{description}

MCMC samplers' step methods can be accessed via the \texttt{\textbf{step_method_dict}} attribute. \texttt{M.step_method_dict[x]} returns a list of the step methods \texttt{M} will use to handle the stochastic variable \texttt{x}.

\section{Step methods} 
\label{sec:stepmethod} 

Step method objects handle individual stochastic variables, or sometimes groups of them. They are responsible for making the variables they handle take single MCMC steps conditional on the rest of the model. Each subclass of \texttt{StepMethod} implements a method called \texttt{step()}, which does this. Step methods with adaptive tuning parameters can optionally implement a method called \texttt{tune()}, which causes them to assess performance so far and adjust.

The major subclasses of \texttt{StepMethod} are \texttt{Metropolis} and \texttt{Gibbs}. PyMC provides several flavors of the basic Metropolis steps, but the Gibbs steps are not implemented in the current release. However, because it is feasible to write Gibbs step methods for particular applications , the \texttt{Gibbs} class will be documented here.


\subsection{Metropolis step methods}
\texttt{Metropolis} and subclasses implement Metropolis-Hastings steps. \texttt{Metropolis} itself handles float-valued variables, and subclasses \texttt{DiscreteMetropolis} and \texttt{BinaryMetropolis} handle integer- and boolean-valued variables, respectively. Subclasses of \texttt{Metropolis} must implement the following methods:
\begin{description}
    \item[\texttt{propose()}:] Sets the values of the stochastic variables handled by the step method to new values.
    \item[\texttt{reject()}:] If the Metropolis acceptance test fails, reset the values of the stochastic variables to their values before \texttt{propose()} was called.
\end{description}
Note that there is no \texttt{accept()} method; if a proposal is accepted, the variables' values are simply left alone. Subclasses that use proposal distributions other than symmetric random-walk may specify the `Hastings factor' by changing the \textbf{\texttt{hastings_factor}} method.

Metropolis step methods have the following useful attributes:
\begin{description}
    \item[\texttt{dist}:] A string indicating which distribution should be used for proposals. Current options are \texttt{'Normal'} and \texttt{'Prior'}.
    \item[\texttt{proposal\_sig}:] Proportional to the standard deviation of the proposal distribution (if it is \texttt{'Normal'}).
    \item[\texttt{\_asf}:] The `adaptive scale factor'. When \texttt{tune()} is called, the acceptance ratio of the step method is examined and this scale factor is updated accordingly. If the proposal distribution is normal, proposals will have standard deviation \texttt{self.proposal\_sig * self.\_asf}. It is usually OK to keep tuning throughout the MCMC loop even though the resulting chain is not actually Markov \cite{tuning}. 
\end{description}

Metropolis step methods can be created as follows:
\begin{verbatim}
M = Metropolis(stochastic, scale=1., sig=None, dist=None, verbose=0)
\end{verbatim}
The \texttt{scale} and \texttt{sig} arguments determine \texttt{proposal\_sig}. If \texttt{sig} is provided, \texttt{proposal\_sig} is set to \texttt{sig}. Otherwise it is computed from \texttt{scale} as follows:
\begin{verbatim}
if all(self.stochastic.value != 0.):
    self.proposal_sig = ones(shape(self.stochastic.value)) * abs(self.stochastic.value) * scale
else:
    self.proposal_sig = ones(shape(self.stochastic.value)) * scale
\end{verbatim}

The \texttt{dist} argument specifies the proposal distribution and may be either of the following strings:
\begin{itemize}
    \item \texttt{"Normal"}: A random-walk normal proposal distribution is used.
    \item \texttt{"Prior"}: The variable's value is proposed from its prior using its \texttt{random} method, if possible.
\end{itemize}
If \texttt{dist=None}, the proposal distribution is chosen automatically.

\subsubsection{The \texttt{DiscreteMetropolis} class}
This class is just like \texttt{Metropolis}, but specialized to handle \texttt{DiscreteStochastic} instances.

\subsubsection{The \texttt{BinaryMetropolis} class} 
This class is specialized to handle \texttt{BinaryStochastic} instances, which are Bernoulli random variables conditional on their parents. 

For scalar-valued variables, \texttt{BinaryMetropolis} behaves like a Gibbs sampler, since this requires no additional expense. The \texttt{p_jump} and \texttt{_asf} parameters are not used in this case.

For array-valued variables, \texttt{BinaryMetropolis} can be set to propose from the prior by passing in \texttt{dist="Prior"}. Otherwise, the argument \texttt{p_jump} of the init method specifies how probable a change is when proposing a new value for array-valued variables. Like \texttt{Metropolis}' attribute \texttt{proposal_sig}, \texttt{p_jump} is tuned throughout the sampling loop via \texttt{_asf}.


\subsubsection{The \texttt{AdaptiveMetropolis} class} 
\textbf{Someone else document this}

\subsection{Gibbs step methods}
Conjugate submodels can be handled by Gibbs step methods rather than the default Metropolis methods. Gibbs step methods are Metropolis methods whose acceptance rate is always 1. They can be convenient because they relieve the user from having to worry about tuning the acceptance rate, but they can be computationally expensive. When variables are highly dependent on one another, better mixing can often be obtained by using \texttt{AdaptiveMetropolis} even when Gibbs step methods for the individual variables are available.

The following conjugate submodels are supported (see \href{http://en.wikipedia.org/wiki/Conjugate_prior}{http://en.wikipedia.org/wiki/Conjugate_prior} ):
\begin{itemize}
    \item Gamma-Gamma
    \item Gamma-Exponential
    \item Gamma-Poisson
    \item Gamma-Normal
    \item Beta-Geometric
    \item Beta-Binomial
    \item Wishart-Multivariate Normal (represented by the \texttt{MvNormal} class, which is parameterized by precision)
    \item Dirichlet-Multinomial.
    \item Normal-Normal (or Normal-MvNormal, etc.) \textbf{[Not yet implemented]}
\end{itemize}

Gibbs step methods have the following class attributes:
\begin{itemize}
    \item \texttt{child_class}: The step method can handle variables whose children are all of this class. \texttt{GammaNormal.child_class} is \texttt{Normal}, for example.
    \item \texttt{parent_label}: The target variable's children must refer to it by this label. \texttt{GammaNormal.parent_label} is \texttt{'mu'}.
    \item \texttt{target_class}: The target variable should be of this class for the submodel to be fully conjugate. \texttt{GammaNormal.target_class} is \texttt{Gamma}.
    \item \texttt{linear_OK}: A flag indicating whether the variable's children can depend on a multiple of the variable. Such multiples must be implemented via the \texttt{Deterministic} subclass \texttt{LinearCombination}.
\end{itemize}

A Gibbs step method can handle variables that are not of their target class, as long as all their children are of the appropriate class. If this is the case, the step method's \texttt{conjugate} attribute will be set to false and its acceptance rate will no longer be 1.

Gibbs step methods can are easy to use manually. To tell an \texttt{MCMC} object $M$ to handle a variable $x$ using the \texttt{GammaNormal} class, simply use the call
\begin{verbatim}
    M.use_step_method(GammaNormal, M)
\end{verbatim}

To indicate a general preference for Gibbs step methods vs. Metropolis step methods, set the following global integer values:
\begin{itemize}
    \item \texttt{pymc.conjugate_Gibbs_competence}: Applicable Gibbs step methods' competence functions will return this value for variables that are not of their target classes. The default value is 3, meaning that these methods will always be assigned when possible. Set this value to 0 to prevent these methods from being assigned automatically, or to 1.5 to set their priorities between those of \texttt{Metropolis} and \texttt{AdaptiveMetropolis}.
    \item \texttt{pymc.nonconjugate_Gibbs_competence}: Applicable Gibbs step methods' competence functions will return this value for variables that are of their target classes. The default value is 0, meaning that these methods are never assigned automaticall.
\end{itemize}


\subsection{Gaussian submodels, all-Gaussian models, and the \texttt{NormalNormal} Gibbs step method}

\subsection{Granularity of step methods: one-at-a-time vs. block updating} 
There is currently no way for an individual stochastic variable to cache individual terms of its log-probability; when this is recomputed, it is recomputed from scratch. This means that updating the elements of a array-valued variable individually is inefficient, so all existing step methods update array-valued variables together, in a block update.

To update an array-valued variable's elements individually, simply break it up into an array of scalar-valued variables. Instead of this:
\begin{verbatim}
A = Normal('A', value = zeros(100), mu=0., tau=1.)    
\end{verbatim}
do this:
\begin{verbatim}
A = [Normal('A[%i]'%i, 0., mu=0., tau=1.) for i in xrange(100)]
\end{verbatim}
An individual step method will be assigned to each element of \texttt{A} in the latter case, and the elements will be updated individually. Note that \texttt{A} can be broken up into larger blocks if desired.

It would be possible to make variables compute their log-probabilities factor-by-factor in the future given sufficient demand, but this might not be a good idea. The expense of cache-checking is significant, so unnecessarily maintaining separate caches for each of an array-valued variable's elements would slow cases where block updating is desired. 

\subsection{Automatic assignment of step methods} 
Every step method subclass (including user-defined ones) adds itself to a list called \texttt{StepMethodRegistry} in the PyMC namespace. If a step method is created by the user to handle a stochastic variable, no other step method will be created to handle that variable by \texttt{MCMC} (though the user can create multiple step methods for the same variable if desired). 

If the user has not created any step method to handle a stochastic variable, each class in \texttt{StepMethodRegistry} is allowed to examine the variable. More specifically, each step method implements a static method called \texttt{competence(stochastic)}, whose only argument is a single stochastic variable. These methods return values from 0 to 3; 0 meaning the step method cannot safely handle the variable and 3 meaning it will most likely perform well for variables like this. \texttt{MCMC} objects assign the step method that returns the highest competence value to each stochastic variable.