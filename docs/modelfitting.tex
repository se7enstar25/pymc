% PyMC probability models are linked collections of nodes. These nodes are only informed by the values of their parents. \code{Deterministic} instances can compute their values given their parents' values, \code{Stochastic} instances can compute their log-probabilities or draw new values, and \code{Potential} instances can compute their log-probabilities. Fitting probability models requires larger-scale coordination and communication.

PyMC provides three objects that fit models:
\begin{itemize}
    \item \code{MCMC}, which coordinates Markov chain Monte Carlo algorithms. The actual work of updating stochastic variables conditional on the rest of the model is done by \code{StepMethod} objects, which are described in this chapter.
    \item \code{MAP}, which computes maximum \emph{a posteriori} estimates.
    \item \code{NormApprox}, which computes the `normal approximation' \citep{gelman}: the joint distribution of all stochastic variables in a model is approximated as normal using local information at the maximum \emph{a posteriori} estimate.
\end{itemize}

All three objects are subclasses of \code{Model}, which is PyMC's base class for fitting methods. \code{MCMC} and \code{NormApprox}, both of which can produce samples from the posterior, are subclasses of \code{Sampler}, which is PyMC's base class for Monte Carlo fitting methods. \code{Sampler} provides a generic sampling loop method and database support for storing large sets of joint samples. These base classes are documented at the end of this chapter. %Sampling loops can optionally be run interactively, meaning the user can pause sampling at any time, return to the Python prompt, check progress, and make adjustments.

\section{Creating models} \label{sec:ModelInstantiation}
The first argument to any fitting method's \code{init} method, including that of \code{MCMC}, is called \code{input}. The \code{input} argument can be just about anything; once you have defined the nodes that make up your model, you shouldn't even have to think about how to wrap them in a \code{Model} instance. Some examples of model instantiation using nodes \code{a}, \code{b} and \code{c} follow:
\begin{itemize}
    \item \code{M = Model(set([a,b,c]))}
    \item \code{M = Model(\{`a': a, `d': [b,c]\})} In this case, $M$ will expose $a$ and $d$ as attributes: \code{M.a} will be $a$, and \code{M.d} will be \code{[b,c]}.
    \item \code{M = Model([[a,b],c])}
    \item If file \code{MyModule} contains the definitions of \code{a}, \code{b} and \code{c}:
   \begin{verbatim}
import MyModule
M = Model(MyModule)
    \end{verbatim}
    In this case, $M$ will expose $a$, $b$ and $c$ as attributes.
    \item Using a `model factory' function:
    \begin{verbatim}
def make_model(x):
    a = pm.Exponential('a',beta=x,value=0.5)

    @pm.deterministic
    def b(a=a):
        return 100-a

    @pm.stochastic
    def c(value=0.5, a=a, b=b):
        return (value-a)**2/b

    return locals()

M = pm.Model(make_model(3))
    \end{verbatim}
    In this case, $M$ will also expose $a$, $b$ and $c$ as attributes.
\end{itemize}

\subsection[The Model class]{The \code{Model} class} \label{sec:Model}
\code{Model} serves as a container for probability models and as a base class for the classes responsible for model fitting, such as \code{MCMC}.

\code{Model}'s init method takes the following arguments:
\begin{description}
    \item[\code{input}:] Some collection of PyMC nodes defining a probability model. These may be stored in a list, set, tuple, dictionary, array, module, or any object with a \code{__dict__} attribute.
    \item[\code{verbose} (optional):] An integer controlling the verbosity of the model's output.
\end{description}

Models' useful methods are:
\begin{description}
    \item[\code{draw_from_prior()}:] Sets all stochastic variables' values to new random values, which would be a sample from the joint distribution if all data and \code{Potential} instances' log-probability functions returned zero. If any stochastic variables lack a \code{random()} method, PyMC will raise an exception.
    \item[\code{seed()}:] Same as \code{draw_from_prior}, but only \code{stochastics} whose \code{rseed} attribute is not \code{None} are changed.
\end{description}

The helper function \code{graph} produces graphical representations of models \cite[see]{Jordan:2004p5439}.

Models have the following important attributes:
\begin{itemize}
    \item \code{variables}
    \item \code{stochastics}
    \item \code{potentials}
    \item \code{deterministics}
    \item \code{observed_stochastics}
    \item \code{step_methods}
    \item \code{value}: A copy of the model, with each attribute that is a PyMC variable or container replaced by its value.
    \item \texttt{generations}: A \href{http://en.wikipedia.org/wiki/Topological_sort}{topological sorting} of the stochastics in the model.
\end{itemize}

In addition, models expose each node they contain as an attribute. For instance, if model \code{M} were produced from model (\ref{disastermodel}) \code{M.s} would return the switchpoint variable.


\section{Maximum \emph{a posteriori} estimates} \label{sec:MAP}

The \code{MAP} class sets all stochastic variables to their maximum \emph{a posteriori} values using functions in SciPy's \code{optimize} package. SciPy must be installed to use it. \code{MAP} can only handle variables whose dtype is \code{float}, so it will not work on model \ref{disastermodel}. To fit the model in \file{examples/gelman_bioassay.py} using \code{MAP}, do the following
\begin{verbatim}
>>> from pymc.examples import gelman_bioassay
>>> M = pm.MAP(gelman_bioassay)
>>> M.fit()
\end{verbatim}
This call will cause $M$ to fit the model using Nelder-Mead optimization, which does not require derivatives. The variables in \code{gelman_bioassay} have now been set to their maximum \emph{a posteriori} values:
\begin{verbatim}
>>> M.alpha.value
array(0.8465892309923545)
>>> M.beta.value
array(7.7488499785334168)
\end{verbatim}
In addition, the AIC and BIC of the model are now available:
\begin{verbatim}
>>> M.AIC
7.9648372671389458
>>> M.BIC
6.7374259893787265
\end{verbatim}

\bigskip
\code{MAP} has two useful methods:
\begin{description}
    \item[\code{fit(method ='fmin', iterlim=1000, tol=.0001)}:] The optimization method may be \code{fmin}, \code{fmin_l_bfgs_b}, \code{fmin_ncg}, \code{fmin_cg}, or \code{fmin_powell}. See the documentation of SciPy's \code{optimize} package for the details of these methods. The \code{tol} and \code{iterlim} parameters are passed to the optimization function under the appropriate names.
    \item[\code{revert_to_max()}:] If the values of the constituent stochastic variables change after fitting, this function will reset them to their maximum \emph{a posteriori} values.
\end{description}
If you're going to use an optimization method that requires derivatives, \code{MAP}'s \code{init} method can take additional parameters \code{eps} and \code{diff_order}. \code{diff_order}, which must be an integer, specifies the order of the numerical approximation (see the SciPy function \code{derivative}). The step size for numerical derivatives is controlled by \code{eps}, which may be either a single value or a dictionary of values whose keys are variables (actual objects, not names).

The useful attributes of \code{MAP} are:
\begin{description}
    \item[\code{logp}:] The joint log-probability of the model.
    \item[\code{logp_at_max}:] The maximum joint log-probability of the model.
    % \item[\code{len}:] The total number of elements in all the stochastic variables in the model with \code{observed=False}.
    % \item[\code{data_len}:] The total number number of elements in all the stochastic variables in the model with \code{observed=True}.
    \item[\code{AIC}:] Akaike's information criterion for this model \citep{Akaike:1973aj,Burnham:2002ic}.
    \item[\code{BIC}:] The Bayesian information criterion for this model \citep{Schwarz:1978ud}.
\end{description}

One use of the \code{MAP} class is finding reasonable initial states for MCMC chains. Note that multiple \code{Model} subclasses can handle the same collection of nodes.

\section{Normal approximations} \label{sec:norm-approx}

The \code{NormApprox} class extends the \code{MAP} class by approximating the posterior covariance of the model using the Fisher information matrix, or the Hessian of the joint log probability at the maximum. To fit the model in \file{examples/gelman_bioassay.py} using \code{NormApprox}, do:
\begin{verbatim}
>>> N = pm.NormApprox(gelman_bioassay)
>>> N.fit()
\end{verbatim}
The approximate joint posterior mean and covariance of the variables are available via the attributes \code{mu} and \code{C}:
\begin{verbatim}
>>> N.mu[N.alpha]
array([ 0.84658923])
>>> N.mu[N.alpha, N.beta]
array([ 0.84658923,  7.74884998])
>>> N.C[N.alpha]
matrix([[ 1.03854093]])
>>> N.C[N.alpha, N.beta]
matrix([[  1.03854093,   3.54601911],
        [  3.54601911,  23.74406919]])
\end{verbatim}
As with \code{MAP}, the variables have been set to their maximum \emph{a posteriori} values (which are also in the \code{mu} attribute) and the AIC and BIC of the model are available.

In addition, it's now possible to generate samples from the posterior as with \code{MCMC}:
\begin{verbatim}
>>> N.sample(100)
>>> N.trace('alpha')[::10]
array([-0.85001278,  1.58982854,  1.0388088 ,  0.07626688,  1.15359581,
       -0.25211939,  1.39264616,  0.22551586,  2.69729987,  1.21722872])
>>> N.trace('beta')[::10]
array([  2.50203663,  14.73815047,  11.32166303,   0.43115426,
        10.1182532 ,   7.4063525 ,  11.58584317,   8.99331152,
        11.04720439,   9.5084239 ])
\end{verbatim}
Any of the database backends can be used (chapter \ref{chap:database}).

\bigskip
In addition to the methods and attributes of \code{MAP}, \code{NormApprox} provides the following methods:
\begin{description}
    \item[\code{sample(iter)}:] Samples from the approximate posterior distribution are drawn and stored.
    \item[\code{isample(iter)}:] An `interactive' version of \code{sample()}: sampling can be paused, returning control to the user.
    \item[\code{draw}:] Sets all variables to random values drawn from the approximate posterior.
\end{description}
It provides the following additional attributes:
\begin{description}
    \item[\code{mu}:] A special dictionary-like object that can be keyed with multiple variables. \code{N.mu[p1, p2, p3]} would return the approximate posterior mean values of stochastic variables \code{p1}, \code{p2} and \code{p3}, ravelled and concatenated to form a vector.
    \item[\code{C}:] Another special dictionary-like object. \code{N.C[p1, p2, p3]} would return the approximate posterior covariance matrix of stochastic variables \code{p1}, \code{p2} and \code{p3}. As with \code{mu}, these variables' values are ravelled and concatenated before their covariance matrix is constructed.
\end{description}

\section[Markov chain Monte Carlo: the MCMC class]{Markov chain Monte
Carlo: the \code{MCMC} class} \label{sec:mcmc}

The \code{MCMC} class implements PyMC's core business: producing `traces' for a model's variables which can be considered sequences of joint samples from the posterior. See chapter \ref{chap:tutorial} for an example of basic usage.

\code{MCMC}'s primary job is to create and coordinate a collection of `step methods', each of which is responsible for updating one or more variables. The available step methods are described below. Instructions on how to create your own step method are available in chapter \ref{chap:extending}.

\code{MCMC} provides the following useful methods:
\begin{description}
    \item[\code{sample(iter, burn, thin, tune\_interval, tune\_throughout, save\_interval, verbose)}:] Runs the MCMC algorithm and produces the traces. The \code{iter} argument controls the total number of MCMC iterations. No tallying will be done during the first \code{burn} iterations; these samples will be forgotten. After this burn-in period, tallying will be done each \code{thin} iterations. Tuning will be done each \code{tune\_interval} iterations. If \code{tune\_throughout=False}, no more tuning will be done after the burnin period. The model state will be saved every \code{save\_interval} iterations, if given.
    \item[\code{isample(iter, burn, thin, tune\_interval, tune\_throughout, save\_interval, verbose)}:] An interactive version of \code{sample}. The sampling loop may be paused at any time, returning control to the user.
    \item[\code{use_step_method(method, *args, **kwargs)}:] Creates an instance of step method class \code{method} to handle some stochastic variables. The extra arguments are passed to the \code{init} method of \code{method}. Assigning a step method to a variable manually will prevent the \code{MCMC} instance from automatically assigning one. However, you may handle a variable with multiple step methods.
    % \item[\code{assign_step_methods()}:] Assigns step methods to all stochastic variables that do not currently have any. This method is called whenever \code{sample} or \code{isample} is called, but it can be useful to call it directly to see what the default step methods will be.

    % A variable is assigned a step method as follows: each eligible \code{StepMethod} subclass in existence is allowed to inspect the variable in question and determine its competence to handle the variable, on a scale of 0 to 3. An instance of the highest bidder is created to handle the variable.
    \item[\code{goodness()}:] Calculates goodness-of-fit (GOF) statistics according to \cite{Brooks:2000il}.
    \item[\code{save\_state()}:] Saves the current state of the sampler, including all stochastics, to the database. This allows the sampler to be reconstituted at a later time to resume sampling. This is not supported yet for the RDBMS backends, sqlite and mysql.
    \item[\code{restore\_state()}:] Restores the sampler to the state stored in the database.
	 \item[\code{stats()}:] Generates summary statistics for all nodes in the model.
    \item[\code{remember(trace\_index)}:] Set all variables' values from frame \code{trace\_index} in the database.
\end{description}

MCMC samplers' step methods can be accessed via the \code{\textbf{step_method_dict}} attribute. \code{M.step_method_dict[x]} returns a list of the step methods \code{M} will use to handle the stochastic variable \code{x}.

After sampling, the information tallied by \code{M}  can be queried via \code{M.db.trace_names}. In addition to the values of variables, tuning information for adaptive step methods is generally tallied. These `traces' can be plotted to verify that tuning has in fact terminated.

You can produce `traces' for arbitrary functions with zero arguments as well. If you issue the command \code{M._funs_to_tally['trace_name'] = f} before sampling begins, then each time the model variables' values are tallied \code{f} will be called with no arguments, and the return value will be tallied. After sampling ends you can retrieve the trace as \code{M.trace['trace_name']}

\subsection[The Sampler class]{The \code{Sampler} class} \label{sec:Sampler}
\code{MCMC} is a subclass of a more general class called \code{Sampler}. Samplers fit models with Monte Carlo fitting methods, which characterize the posterior distribution by approximate samples from it. They are initialized as follows: \code{Sampler(input=None, db='ram', name='Sampler', reinit_model=True, calc_deviance=False)}. The \code{input} argument is a module, list, tuple, dictionary, set, or object that contains all elements of the model, the \code{db} argument indicates which database backend should be used to store the samples (see chapter \ref{chap:database}), \code{reinit\_model} is a boolean flag that indicates whether the model should be re-initialised before running, and \code{calc\_deviance} is a boolean flag indicating whether deviance should be calculated for the model at each iteration. Samplers have the following important methods:
\begin{description}
    \item[\code{sample(iter, length=None, verbose=0)}:] Samples from the joint distribution. The \code{iter} argument controls how many times the sampling loop will be run, and the \code{length} argument controls the initial size of the database that will be used to store the samples.
    \item[\code{isample(iter, length=None, verbose=0)}:] The same as \code{sample}, but the sampling is done interactively: you can pause sampling at any point and be returned to the Python prompt to inspect progress and adjust fitting parameters. While sampling is paused, the following methods are useful:
    \begin{description}
        \item[\code{icontinue()}:] Continue interactive sampling.
        \item[\code{halt()}:] Truncate the database and clean up.
    \end{description}
    \item[\code{tally()}:] Write all variables' current values to the database. The actual write operation depends on the specified database backend.
    %\item[\code{draw()}:] Not currently used. In future Monte Carlo fitting methods that aren't MCMC, such as importance samplers, the \code{draw()} method will be responsible for drawing approximate samples from the joint distribution (by setting the values of all the stochastic variables in the model).
    \item[\code{save\_state()}:] Saves the current state of the sampler, including all stochastics, to the database. This allows the sampler to be reconstituted at a later time to resume sampling. This is not supported yet for the RDBMS backends, sqlite and mysql.
    \item[\code{restore\_state()}:] Restores the sampler to the state stored in the database.
	 \item[\code{stats()}:] Generates summary statistics for all nodes in the model.
    \item[\code{remember(trace\_index)}:] Set all variables' values from frame \code{trace\_index} in the database. Note that the \code{trace_index} is different from the current iteration, since not all samples are necessarily saved due to burning and thinning.
\end{description}

In addition, the sampler attribute \code{deviance} is a deterministic variable valued as the model's deviance at its current state.


\section{Step methods} \label{sec:stepmethod}


Step method objects handle individual stochastic variables, or sometimes groups of them. They are responsible for making the variables they handle take single MCMC steps conditional on the rest of the model. Each subclass of \code{StepMethod} implements a method called \code{step()}, which is called by \code{MCMC}. Step methods with adaptive tuning parameters can optionally implement a method called \code{tune()}, which causes them to assess performance so far and adjust.

The major subclasses of \code{StepMethod} are \code{Metropolis},
\code{AdaptiveMetropolis} and \code{Gibbs}. PyMC provides several flavors of the
basic Metropolis steps, but the Gibbs steps are not ready for use as of the
current release. However, because it is feasible to write Gibbs step methods
for particular applications, the \code{Gibbs} base class will be documented
here.

\subsection{Metropolis step methods} \label{metropolis}

\code{Metropolis} and subclasses implement Metropolis-Hastings steps. To tell an \code{MCMC} object $M$ to handle a variable $x$ with a Metropolis step method, you might do the following:
\begin{verbatim}
M.use_step_method(pm.Metropolis, x, proposal_sd=1., proposal_distribution='Normal')
\end{verbatim}

\code{Metropolis} itself handles float-valued variables, and subclasses \code{DiscreteMetropolis} and \code{BinaryMetropolis} handle integer- and boolean-valued variables, respectively. Subclasses of \code{Metropolis} must implement the following methods:
\begin{description}
    \item[\code{propose()}:] Sets the values of the variables handled by the Metropolis step method to proposed values.
    \item[\code{reject()}:] If the Metropolis-Hastings acceptance test fails, this method is called to reset the values of the variables to their values before \code{propose()} was called.
\end{description}
Note that there is no \code{accept()} method; if a proposal is accepted, the variables' values are simply left alone. Subclasses that use proposal distributions other than symmetric random-walk may specify the `Hastings factor' by changing the \code{hastings\_factor} method. See chapter \ref{chap:extending} for an example.

\code{Metropolis}' \texttt{init} method takes the following arguments:
\begin{description}
   \item[\code{stochastic}:] The variable to handle.
   \item[\code{proposal_sd}:] A float or array of floats. This sets the
    default proposal standard deviation if the proposal distribution is normal.
   \item[\code{scale}:] A float, defaulting to 1. If the \code{scale} argument is provided but not \code{proposal_sd}, \code{proposal\_sd} is computed as follows:
   \begin{verbatim}
   if all(self.stochastic.value != 0.):
       self.proposal_sd = ones(shape(self.stochastic.value)) * \
                           abs(self.stochastic.value) * scale
   else:
       self.proposal_sd = ones(shape(self.stochastic.value)) * scale
   \end{verbatim}
   \item[\code{proposal_distribution}:] A string indicating which distribution should be used for proposals. Current options are \code{'Normal'} and \code{'Prior'}. If \code{proposal_distribution=None}, the proposal distribution is chosen automatically. It is set to \code{'Prior'} if the variable has no children and has a random method, and to \code{'Normal'} otherwise.
   \item[\code{verbose}:] An integer. By convention, $0$ indicates minimal output and $2$ indicates maximum verbosity.
\end{description}

Although the \code{proposal\_sd} attribute is fixed at creation, Metropolis step methods adjust this initial value using an attribute called \code{adaptive_scale_factor}. When \code{tune()} is called, the acceptance ratio of the step method is examined and this scale factor is updated accordingly. If the proposal distribution is normal, proposals will have standard deviation \code{self.proposal\_sd * self.adaptive_scale_factor}.

By default, tuning will continue throughout the sampling loop, even after the burnin period is over. This can be changed via the \texttt{tune\_throughout} argument to \texttt{MCMC.sample}. If an adaptive step method's \texttt{tally} flag is set (the default for \texttt{Metropolis}), a trace of its tuning parameters will be kept. If you allow tuning to continue throughout the sampling loop, it is important to verify that the `Diminishing Tuning' condition of \cite{tuning} is satisfied: the amount of tuning should decrease to zero, or tuning should become very infrequent.

If a Metropolis step method handles an array-valued variable, it proposes all elements independently but simultaneously. That is, it decides whether to accept or reject all elements together but it does not attempt to take the posterior correlation between elements into account. The \code{AdaptiveMetropolis} class (see below), on the other hand, does make correlated proposals.

\subsubsection[The AdaptiveMetropolis class]{The
\code{AdaptiveMetropolis} class}
\label{subsec:AM}
The \code{AdaptativeMetropolis} (AM) step method works like a regular Metropolis
step method, with the exception that its variables are block-updated using a
multivariate jump distribution whose covariance is tuned during sampling.
Although the chain is non-Markovian, it has correct ergodic properties (see
\cite{Haario:2001lr}).

To tell an \code{MCMC} object $M$ to handle variables $x$, $y$ and $z$ with an
\code{AdaptiveMetropolis} instance, you might do the following:
\begin{verbatim}
   M.use_step_method(pm.AdaptiveMetropolis, [x,y,z], \
                      scales={x:1, y:2, z:.5}, delay=10000)
\end{verbatim}

\code{AdaptativeMetropolis}' init method takes the following arguments:
% cov=None, delay=1000, scales=None, interval=200, greedy=True,verbose=0
\begin{description}
   \item[\code{stochastics}:] The stochastic variables to handle. These will be
updated jointly.
   \item[\code{cov} (optional):] An initial covariance matrix. Defaults to the
identity matrix, adjusted according to the \code{scales} argument.
   \item[\code{delay} (optional):] The number of iterations to delay before
computing the empirical covariance matrix.
   \item[\code{scales} (optional):] The initial covariance matrix will be
diagonal, and its diagonal elements will be set to \code{scales} times the
stochastics' values, squared.
   \item[\code{interval} (optional):] The number of iterations between updates
of the covariance matrix. Defaults to 1000.
   \item[\code{greedy} (optional):] If \code{True}, only accepted jumps will be
counted toward the delay before the covariance is first computed. Defaults to
\code{True}.
   \item[\code{verbose} (optional):] An integer from 0 to 3 controlling the verbosity of
the step method's printed output.
    \item[\code{shrink_if_necessary} (optional):] Whether the proposal covariance should be
shrunk if the acceptance rate becomes extremely small.
\end{description}

In this algorithm, jumps are proposed from a multivariate normal
distribution with covariance matrix $C$. The algorithm first iterates
until \code{delay} samples have been drawn (if \code{greedy} is true, until
\code{delay} jumps have been accepted). At this point, $C$ is given
the value of the empirical covariance of the trace so far and sampling
resumes. The covariance is then updated each \code{interval}
iterations throughout the entire sampling run\footnote{The covariance is
estimated recursively from the previous value and the last \code{interval}
samples, instead of computing it each time from the entire trace.}. It is
this constant adaptation of the proposal distribution that makes the chain
non-Markovian.

\subsubsection[The DiscreteMetropolis class]{The
\code{DiscreteMetropolis} class}
This class is just like \code{Metropolis}, but specialized to handle
\code{Stochastic} instances with dtype \code{int}. The jump proposal
distribution can either be \code{'Normal'}, \code{'Prior'} or \code{'Poisson'}.
In the normal case, the proposed value is drawn from a normal distribution
centered at the current value and then rounded to the
nearest integer. In the Poisson case, the proposed value is obtained by adding
or substracting (with equal probability) a random value drawn from a Poisson
distribution.

\subsubsection[The BinaryMetropolis class]{The
\code{BinaryMetropolis} class}
This class is specialized to handle \code{Stochastic} instances with dtype
\code{bool}.

For array-valued variables, \code{BinaryMetropolis} can be set to propose from
the prior by passing in \code{dist="Prior"}. Otherwise, the argument
\code{p_jump} of the init method specifies how probable a change is. Like
\code{Metropolis}' attribute \code{proposal_sd}, \code{p_jump} is tuned
throughout the sampling loop via \code{adaptive_scale_factor}.

For scalar-valued variables, \code{BinaryMetropolis} behaves like a Gibbs
sampler, since this requires no additional expense. The \code{p_jump} and
\code{adaptive_scale_factor} parameters are not used in this case.

% ==========================================================
% = We can uncomment this when we actually release them... =
% ==========================================================
% \hypertarget{gibbs}{}
% \subsection{Gibbs step methods} \label{gibbs}
% \pdfbookmark[1]{Gibbs step methods}{gibbs}
%
% Conjugate submodels (see \cite{gelman}) can be handled by Gibbs step methods rather than the default Metropolis methods. Gibbs step methods are Metropolis methods whose acceptance rate is always 1. They can be convenient because they relieve the user from having to worry about tuning the acceptance rate, but they can be computationally expensive. When variables are highly dependent on one another, better mixing can often be obtained by using \code{AdaptiveMetropolis} even when Gibbs step methods are available.
%
% Alpha versions of Gibbs step methods handling the following conjugate submodels are available in the \code{sandbox} module, but they are not recommended and will not be assigned automatically:
% \begin{itemize}
%     \item Gamma-Gamma
%     \item Gamma-Exponential
%     \item Gamma-Poisson
%     \item Gamma-Normal
%     \item Beta-Geometric
%     \item Beta-Binomial
%     \item Wishart-Multivariate Normal (represented by the \code{MvNormal} class, which is parameterized by precision)
%     \item Dirichlet-Multinomial.
%     \item Normal-Normal (or Normal-MvNormal, etc.) (requires \code{cvxopt}, \href{http://abel.ee.ucla.edu/cvxopt}{http://abel.ee.ucla.edu/cvxopt} )
% \end{itemize}
% However, if you implement a custom Gibbs step method, subclassing the \code{Gibbs} class will ensure interopera
%
% Gibbs step methods have the following class attributes:
% \begin{itemize}
%     \item \code{child_class}: The step method can handle variables whose children are all of this class. \code{GammaNormal.child_class} is \code{Normal}, for example.
%     \item \code{parent_label}: The target variable's children must refer to it by this label. \code{GammaNormal.parent_label} is \code{'mu'}.
%     \item \code{target_class}: The target variable should be of this class for the submodel to be fully conjugate. \code{GammaNormal.target_class} is \code{Gamma}.
%     \item \code{linear_OK}: A flag indicating whether the variable's children can depend on a multiple of the variable. Such multiples must be implemented via the \code{Deterministic} subclass \code{LinearCombination}.
% \end{itemize}
%
% A Gibbs step method can handle variables that are not of their target class, as long as all their children are of the appropriate class. If this is the case, the step method's \code{conjugate} attribute will be set to \code{False} and its acceptance rate will no longer be 1.
%
% Gibbs step methods are easy to use manually. To tell an \code{MCMC}
% object $M$ to handle a variable $x$ using the \code{GammaNormal} class,
% simply use the call
% \begin{verbatim}
%     M.use_step_method(GammaNormal, x)
% \end{verbatim}
%
% To indicate a general preference for Gibbs step methods vs. Metropolis step methods, set the following global integer values:
% \begin{itemize}
%     \item \code{pymc.conjugate_Gibbs_competence}: Applicable Gibbs step methods' competence functions will return this value for variables that are not of their target classes. The default value is 0, meaning that these methods will never be assigned automatically. Set this value to 3 to ensure that Gibbs step methods are always be assigned to conjugate submodels, or to 1.5 to set their priorities between those of \code{Metropolis} and \code{AdaptiveMetropolis}.
%     \item \code{pymc.nonconjugate_Gibbs_competence}: Applicable Gibbs step methods' competence functions will return this value for variables that are of their target classes. The default value is 0, meaning that these methods are never assigned automatically.
% \end{itemize}
%

\subsection{Granularity of step methods: one-at-a-time vs. block updating}
\label{subsec:granularity}
There is currently no way for a stochastic variable to compute individual terms of its log-probability; it is computed all together. This means that updating the elements of a array-valued variable individually would be inefficient, so all existing step methods update array-valued variables together, in a block update.

To update an array-valued variable's elements individually, simply break it up into an array of scalar-valued variables. Instead of this:
\begin{verbatim}
A = pm.Normal('A', value=numpy.zeros(100), mu=0., tau=1.)
\end{verbatim}
do this:
\begin{verbatim}
A = [pm.Normal('A_%i'%i, value=0., mu=0., tau=1.) for i in range(100)]
\end{verbatim}
An individual step method will be assigned to each element of \code{A} in the latter case, and the elements will be updated individually. Note that \code{A} can be broken up into larger blocks if desired.

\subsection{Automatic assignment of step methods}
Every step method subclass (including user-defined ones) that does not require any \texttt{init} arguments other than the stochastic variable to be handled adds itself to a list called \code{StepMethodRegistry} in the PyMC namespace. If a stochastic variable in an \code{MCMC} object has not been explicitly assigned a step method, each class in \code{StepMethodRegistry} is allowed to examine the variable.

To do so, each step method implements a class method called \code{competence}, whose only argument is a single stochastic variable. These methods return values from 0 to 3; 0 meaning the step method cannot safely handle the variable and 3 meaning it will most likely be the best available step method for variables like this. The \code{MCMC} object assigns the step method that returns the highest competence value to each of its stochastic variables.

