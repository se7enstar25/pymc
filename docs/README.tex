




%___________________________________________________________________________

\hypertarget{purpose}{}
\section{Purpose}
\label{purpose}

PyMC is a python module that implements Bayesian statistical models and
fitting algorithms, including Markov chain Monte Carlo.
Its flexibility makes it applicable to a large suite of problems as well as
easily extensible. Along with core sampling functionality, PyMC includes
methods for summarizing output, plotting, goodness-of-fit and convergence
diagnostics.


%___________________________________________________________________________

\hypertarget{features}{}
\section{Features}
\label{features}
\begin{itemize}
\item {} 
Fits Bayesian statistical models you create with Markov chain Monte Carlo and
other algorithms.

\item {} 
Large suite of well-documented statistical distributions.

\item {} 
Gaussian processes.

\item {} 
Sampling loops can be paused and tuned manually, or saved and restarted later.

\item {} 
Creates summaries including tables and plots.

\item {} 
Traces can be saved to the disk as plain text, Python pickles, SQLite or MySQL
database, or hdf5 archives.

\item {} 
Convergence diagnostics.

\item {} 
Extensible: easily incorporates custom step methods and unusual probability
distributions.

\item {} 
MCMC loops can be embedded in larger programs, and results can be analyzed
with the full power of Python.

\end{itemize}


%___________________________________________________________________________

\hypertarget{what-s-new-in-2-0}{}
\section{What's new in 2.0}
\label{what-s-new-in-2-0}
\begin{itemize}
\item {} 
New flexible object model and syntax (not backward-compatible).

\item {} 
Reduced redundant computations: only relevant log-probability terms are
computed, and these are cached.

\item {} 
Optimized probability distributions.

\item {} 
New adaptive blocked Metropolis step method.

\item {} 
Much more!

\end{itemize}


%___________________________________________________________________________

\hypertarget{usage}{}
\section{Usage}
\label{usage}

First, define your model in a file, say mymodel.py (with comments, of course!):
\begin{quote}{\ttfamily \raggedright \noindent
{\#}~Import~relevant~modules~\\
import~pymc~\\
import~numpy~as~np~\\
~\\
{\#}~Some~data~\\
n~=~5*np.ones(4,dtype=int)~\\
x~=~np.array({[}-.86,-.3,-.05,.73{]})~\\
~\\
{\#}~Priors~on~unknown~parameters~\\
alpha~=~pymc.Normal('alpha',mu=0,tau=.01)~\\
beta~=~pymc.Normal('beta',mu=0,tau=.01)~\\
~\\
{\#}~Arbitrary~deterministic~function~of~parameters~\\
@pymc.deterministic~\\
def~theta(a=alpha,~b=beta):~\\
~~~~"{}"{}"theta~=~logit{\textasciicircum}{\{}-1{\}}(a+b)"{}"{}"~\\
~~~~return~pymc.invlogit(a+b*x)~\\
~\\
{\#}~Binomial~likelihood~for~data~\\
d~=~pymc.Binomial('d',~n=n,~p=theta,~value=np.array({[}0.,1.,3.,5.{]}),~observed=True)
}\end{quote}

Save this file, then from a python shell (or another filein the same directory), call:
\begin{quote}{\ttfamily \raggedright \noindent
import~pymc~\\
import~mymodel~\\
~\\
S~=~pymc.MCMC(mymodel,~db='pickle')~\\
S.sample(iter=10000,~burn=5000,~thin=2)~\\
pymc.Matplot.plot(S)
}\end{quote}

This will generate 10000 posterior samples, thinned by a factor of 2, with the first half discarded as burn-in. The sample is stored in a Python serialization (pickle) database.


%___________________________________________________________________________

\hypertarget{history}{}
\section{History}
\label{history}

PyMC began development in 2003, as an effort to generalize the process of building Metropolis-Hastings samplers, with an aim to making Markov chain Monte Carlo (MCMC) more accessible to non-statisticians (particularly ecologists). The choice to develop PyMC as a python module, rather than a standalone application, allowed the use MCMC methods in a larger modeling framework. By 2005, PyMC was reliable enough for version 1.0 to be released to the public. A small group of regular users, most associated with the University of Georgia, provided much of the feedback necessary for the refinement of PyMC to a usable state.

In 2006, David Huard and Anand Patil joined Chris Fonnesbeck on the development team for PyMC 2.0. This iteration of the software strives for more flexibility, better performance and a better end-user experience than any previous version of PyMC.


%___________________________________________________________________________

\hypertarget{getting-started}{}
\section{Getting started}
\label{getting-started}

This user guide provides all the information needed to install PyMC, code
a Bayesian statistical model, run the sampler, save and analyze the results.
In addition, the appendix contains a chapter on MCMC theory as well as the list of the
available statistical distributions. More \href{http://code.google.com/p/pymc/}{examples} of usage as well as
\href{http://code.google.com/p/pymc/wiki/TutorialsAndRecipes}{tutorials}  are available from the PyMC web site.


%___________________________________________________________________________

