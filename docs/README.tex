




%___________________________________________________________________________

\hypertarget{purpose}{}
\pdfbookmark[0]{Purpose}{purpose}
\section*{Purpose}

PyMC is a python module that implements Bayesian statistical models and
fitting algorithms, including Markov chain Monte Carlo, using Python classes. 
Its flexibility makes it applicable to a large suite of problems. Along with 
core sampling functionality, PyMC includes methods for summarizing output, plotting, 
goodness-of- fit and convergence diagnostics.


%___________________________________________________________________________

\hypertarget{features}{}
\pdfbookmark[0]{Features}{features}
\section*{Features}
\begin{itemize}
\item {} 
Fits Bayesian statistical models you create with Markov chain Monte Carlo and 
other algorithms.

\item {} 
Sampling loops can be paused and tuned manually, or saved and restarted later.

\item {} 
Large suite of well-documented statistical distributions.

\item {} 
Creates summaries including tables and plots.

\item {} 
Convergence diagnostics.

\item {} 
Traces can be saved to the disk as plain text, Python pickles, SQLite or MySQL
database, or hdf5 archives. The hdf5 option allows traces to be streamed
to the disk during sampling, reducing memory usage.

\item {} 
Extensible: easily incorporates custom step methods and unusual probability 
distributions and stochastic processes.

\item {} 
MCMC loops can be embedded in larger programs, and results can be analyzed 
with the full power of Python.

\end{itemize}


%___________________________________________________________________________

\hypertarget{what-s-new-in-2-0}{}
\pdfbookmark[0]{What's new in 2.0}{what-s-new-in-2-0}
\section*{What's new in 2.0}
\begin{itemize}
\item {} 
New flexible object model and syntax (non backward compatible).

\item {} 
Reduced redundant computations: only relevant log-probability terms are 
computed, and these are cached.

\item {} 
Optimized probability distributions.

\item {} 
New adaptive blocked Metropolis step method.

\item {} 
Much more!

\end{itemize}


%___________________________________________________________________________

\hypertarget{usage}{}
\pdfbookmark[0]{Usage}{usage}
\section*{Usage}

First, define your model in a file, say mymodel.py (with comments, of course!). Here is a simple example, a binomial model with probability of success expressed as a logit-linear function of some covariate:
\begin{quote}{\ttfamily \raggedright \noindent
{\#}~Import~relevant~modules~\\
import~pymc~\\
import~numpy~as~np~\\
~\\
{\#}~Some~data~\\
n~=~5*np.ones(4,dtype=int)~\\
x~=~np.array({[}-.86,-.3,-.05,.73])~\\
~\\
{\#}~Priors~on~unknown~parameters~\\
alpha~=~pymc.Normal('alpha',mu=0,tau=.01)~\\
beta~=~pymc.Normal('beta',mu=0,tau=.01)~~~~\\
~\\
{\#}~Arbitrary~deterministic~function~of~parameters~\\
@pymc.deterministic~\\
def~theta(a=alpha,~b=beta):~\\
~~~~"{}"{}"theta~=~logit{\textasciicircum}{\{}-1{\}}(a+b)"{}"{}"~\\
~~~~return~pymc.invlogit(a+b*x)~\\
~\\
{\#}~Binomial~likelihood~for~data~\\
d~=~pymc.Binomial('d',~n=n,~p=theta,~value=np.array({[}0.,1.,3.,5.]),~isdata=True)
}\end{quote}

From a python shell (or another file), call:
\begin{quote}{\ttfamily \raggedright \noindent
import~pymc~\\
import~mymodel~\\
~\\
S~=~pymc.MCMC(mymodel,~db='pickle')~\\
S.sample(iter=10000,~burn=5000,~thin=2)~\\
pymc.Matplot.plot(S)
}\end{quote}

This will generate 10000 posterior samples, with the first half discarded as burn-in. The sample is stored in a Python serialization (pickle) database.


%___________________________________________________________________________

\hypertarget{history}{}
\pdfbookmark[0]{History}{history}
\section*{History}

PyMC began development in 2003, as an effort to generalize the process of building Metropolis-Hastings samplers, with an aim to making Markov chain Monte Carlo more accessible to non-statisticians (particularly ecologists). The choice to develop PyMC as a python module, rather than a standalone application, allowed the use MCMC methods in a larger modeling framework, in contrast to the BUGS environment. By 2005, PyMC was reliable enough for version 1.0 to be released to the public. A small group of regular users, most associated with the University of Georgia, provided much of the feedback necessary for the refinement of PyMC to its current state.

In 2006, David Huard and Anand Patil joined Chris Fonnesbeck on the development team for PyMC 2.0. This iteration of the software strives for more flexibility, better performance and a better end-user experience than any previous version of PyMC.


%___________________________________________________________________________

