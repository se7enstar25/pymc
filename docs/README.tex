




%___________________________________________________________________________

\hypertarget{purpose}{}
\pdfbookmark[0]{Purpose}{purpose}
\section*{Purpose}
\label{purpose}

PyMC is a python module that implements the Metropolis-Hastings algorithm as a
python class. It is extremely flexible and applicable to a large suite of
problems. PyMC includes methods for summarizing output, plotting, goodness-of-
fit and convergence diagnostics.


%___________________________________________________________________________

\hypertarget{features}{}
\pdfbookmark[0]{Features}{features}
\section*{Features}
\label{features}
\begin{itemize}
\item {} 
Implements the Metropolis-Hastings algorithm so you can focus on your
application instead of on gory numerical algorithms.

\item {} 
Define your distribution from 24 well-documented statistical distributions,

\item {} 
Summarize your results in tables and plots.

\item {} 
Run convergence diagnostics.

\end{itemize}


%___________________________________________________________________________

\hypertarget{what-s-new-in-2-0}{}
\pdfbookmark[0]{What's new in 2.0}{what-s-new-in-2-0}
\section*{What's new in 2.0}
\label{what-s-new-in-2-0}
\begin{itemize}
\item {} 
Faster internal logic by coding the bottlenecks with Pyrex.

\item {}
More efficient computations by taking advantage of Markov properties of models.

\item {} 
Faster distributions by an optimization of the Fortran functions.

\item {} 
Modular and extensible MCMC system, with several new Metropolis methods provided.

\item {}
Maximum-a-posteriori estimators and normal approximations for approximate model-fitting.

\item {} 
Define your problem in many ways, possibly in a separate file, using classes representing deterministic and stochastic variables and factor potentials. Use decorators to improve code readability. Incorporate arbitrary distributions easily.

\item {} 
Save your samples directly to a database. Select one from sqlite, MySQL, HDF5,
pickle files, text files or write a custom database backend from a template.

\item {} 
Run interactive convergence diagnostics.

\item {} 
Stop a sampling run in the middle, save its state and restart the sampler
later.

\item {} 
Seed multiple chains on different processors.

\end{itemize}


%___________________________________________________________________________

\hypertarget{usage}{}
\pdfbookmark[0]{Usage}{usage}
\section*{Usage}
\label{usage}

From a python shell, type:
\begin{quote}{\ttfamily \raggedright \noindent
import~PyMC~\\
S~=~PyMC.Sampler(problem{\_}definition,~db='pickle')~\\
S.sample(iter=10000,~burn=5000,~thin=2)
}\end{quote}

where problem{\_}definition is a module, dictionary, set, tuple, or list containing Deterministic, Data,
Stochastic and Potential instances defining your problem. If problem{\_}definition is None, these objects will be gathered from the base namespace.


%___________________________________________________________________________

\hypertarget{history}{}
\pdfbookmark[0]{History}{history}
\section*{History}
\label{history}

PyMC began development in 2003, as an effort to generalize the process of building Metropolis-Hastimgs samplers, with an aim to making Markov chain Monte Carlo more accessible to non-statisticians (particularly ecologists). The choice to develop PyMC as a python module, rather than a standalone application, allowed the use MCMC methods in a larger modeling framework, in contrast to the BUGS environment. By 2005, PyMC was reliable enough for version 1.0 to be released to the public. A small group of regular users, most associated with the University of Georgia, provided much of the feedback necessary for the refinement of PyMC to its current state.

In 2006, David Huard and Anand Patil joined Chris Fonnesbeck on the development team for PyMC 2.0. This iteration of the software strives for more flexibility, better performance and a better end-user experience than any previous version of PyMC.


%___________________________________________________________________________

\